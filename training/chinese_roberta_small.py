# -*- coding: utf-8 -*-
"""chinese roberta small

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10-p2xaBAO1MKQPVC6LYHiTAkvTcBNjYK

## Set up

### Install packages
"""

!pip install simpletransformers

"""### Retrieve the data

*Used the following [code](https://github.com/SunYanCN/bert-text/blob/master/src/dataset/chnsenticorp.py) and changed it to make it work*
"""

import codecs
import csv
import os

import pandas as pd
import tensorflow as tf

URL = "https://paddlehub-dataset.bj.bcebos.com/chnsenticorp.tar.gz"


class DataLoader:
    def __init__(self):
        self.dataset_dir = os.path.join(".", "datasets/chnsenticorp")
        file_path = tf.keras.utils.get_file(
            fname="chnsenticorp.tar.gz",
            origin=URL,
            extract=True,
            cache_dir=".",
        )
        
        self.load_data()
    

    def load_data(self):
        self.train_file = os.path.join(self.dataset_dir, "train.tsv")
        self.train_df = self.get_df_from_file(self.train_file)
        self.train_num = len(self.train_df)

        self.dev_file = os.path.join(self.dataset_dir, "dev.tsv")
        self.dev_df = self.get_df_from_file(self.dev_file)
        self.dev_num = len(self.dev_df)

        self.test_file = os.path.join(self.dataset_dir, "test.tsv")
        self.test_df = self.get_df_from_file(self.test_file)
        self.test_df["labels"] = self.test_df["labels"].apply(lambda x: x[0])
        self.test_num = len(self.test_df)

    def get_train_df(self):
        return self.train_df

    def get_dev_df(self):
        return self.dev_df

    def get_test_df(self):
        return self.test_df

    def get_labels(self):
        return ["0", "1"]

    @property
    def num_labels(self):
        """
        Return the number of labels in the dataset.
        """
        return len(self.get_labels())

    def get_df_from_file(self, input_file, quotechar=None):
        with codecs.open(input_file, "r", encoding="UTF-8") as f:
            reader = csv.reader(f, delimiter="\t", quotechar=quotechar)
            data = []
            seq_id = 0
            header = next(reader)  # skip header
            for line in reader:
                data.append([line[1], line[0]])
                seq_id += 1
            df = pd.DataFrame(data)
            df.columns = ["text", "labels"]
            df["labels"] = df["labels"].apply(lambda x: list(map(int, x)))
            return df

    def print_info(self):
        print("training data:")
        print(self.get_train_df().head())
        print("\n")

        print("dev data:")
        print(self.get_dev_df().head())
        print("\n")
        
        print("test data:")
        print(self.get_test_df().head())
        print("\n")

        print("Train number:{}, Dev number:{}, Test number:{}".format(self.train_num, self.dev_num, self.test_num))


data = DataLoader()
data.print_info()

"""## Make the model

### Train a Bert base Chinese classifier on our training data
"""

from simpletransformers.classification import ClassificationModel

# define hyperparameter
train_args ={"reprocess_input_data": True,
             "overwrite_output_dir": True,
             "fp16":False,
             "num_train_epochs": 4}

# Create a ClassificationModel
model = ClassificationModel(
    "bert", "clue/roberta_chinese_clue_tiny",
    num_labels=data.num_labels,
    args=train_args
)

model.train_model(data.get_train_df())

"""### Save the model to outputs

"""

import os
import tarfile

def save_model(model_path='',file_name=''):
  files = [files for root, dirs, files in os.walk(model_path)][0]
  with tarfile.open(file_name+ '.tar.gz', 'w:gz') as f:
    for file in files:
      f.add(f'{model_path}/{file}')

save_model('outputs','chinese-roberta-tiny')

"""### Define how to retrieve model """

import os
import tarfile

def unpack_model(model_name=''): 
  tar = tarfile.open(f"{model_name}.tar.gz", "r:gz")
  tar.extractall()
  tar.close()

"""## Evaluate model

### Retrieve model
"""

unpack_model('chinese-roberta-tiny')

from simpletransformers.classification import ClassificationModel

# define hyperparameter
train_args ={"reprocess_input_data": True,
             "overwrite_output_dir": True,
             "fp16":False,
             "num_train_epochs": 4}

# Create a ClassificationModel
model = ClassificationModel(
    "bert", "outputs/",
    num_labels=data.num_labels,
    args=train_args
)

"""### Test model"""

result, model_outputs, wrong_predictions =model.eval_model(data.get_test_df())
accuracy = (result['tp'] + result['tn'])/data.test_num
print(accuracy)

